{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "473fb3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88d2dbc",
   "metadata": {},
   "source": [
    "###  Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e44366dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2004_2017 = pd.read_csv('C:/Users/vaish/OneDrive/Desktop/python projects/Drug-addiction-analysis/Data/Multiple Cause of Death, 2004-2017.csv')\n",
    "dataset_2018_2023 = pd.read_csv('C:/Users/vaish/OneDrive/Desktop/python projects/Drug-addiction-analysis/Data/Multiple Cause of Death, 2018-2023.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7881b99",
   "metadata": {},
   "source": [
    "### Standardize column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4bed49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2004_2017 = dataset_2004_2017.rename(columns={\n",
    "    'Race': 'Single Race 6',\n",
    "    'Race Code': 'Single Race 6 Code'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f599de8d",
   "metadata": {},
   "source": [
    "### Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9056f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opioid_deaths = pd.concat([dataset_2005_2017, dataset_2018_2023], \n",
    "                          ignore_index=True)\n",
    "\n",
    "\n",
    "#Sort by State, Year, Race, Age Group\n",
    "opioid_deaths = opioid_deaths.sort_values([\n",
    "    'State', 'Year', 'Single Race 6', 'Ten-Year Age Groups'\n",
    "]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39ef58eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year range: 2004.0 - 2023.0\n",
      "Duplicate rows found: 1950\n",
      "Records per year:\n",
      "Year\n",
      "2004.0    334\n",
      "2005.0    343\n",
      "2006.0    369\n",
      "2007.0    387\n",
      "2008.0    382\n",
      "2009.0    389\n",
      "2010.0    382\n",
      "2011.0    399\n",
      "2012.0    418\n",
      "2013.0    424\n",
      "2014.0    435\n",
      "2015.0    467\n",
      "2016.0    486\n",
      "2017.0    515\n",
      "2018.0    613\n",
      "2019.0    651\n",
      "2020.0    745\n",
      "2021.0    812\n",
      "2022.0    854\n",
      "2023.0    881\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# To check year range\n",
    "print(f\"Year range: {opioid_deaths['Year'].min()} - {opioid_deaths['Year'].max()}\")\n",
    "\n",
    "# To check for duplicate rows\n",
    "duplicates = opioid_deaths.groupby([\n",
    "    'State', 'Year', 'Single Race 6', 'Ten-Year Age Groups'\n",
    "]).size().reset_index(name='count')\n",
    "duplicates = duplicates[duplicates['count'] > 1]\n",
    "print(f\"Duplicate rows found: {len(duplicates)}\")\n",
    "\n",
    "\n",
    "# To verify record counts\n",
    "year_counts = opioid_deaths['Year'].value_counts().sort_index()\n",
    "print(\"Records per year:\")\n",
    "print(year_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2ca54d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique races per year:\n",
      "Year\n",
      "2004.0    4\n",
      "2005.0    4\n",
      "2006.0    4\n",
      "2007.0    4\n",
      "2008.0    4\n",
      "2009.0    4\n",
      "2010.0    4\n",
      "2011.0    4\n",
      "2012.0    4\n",
      "2013.0    4\n",
      "2014.0    4\n",
      "2015.0    4\n",
      "2016.0    4\n",
      "2017.0    4\n",
      "2018.0    5\n",
      "2019.0    4\n",
      "2020.0    5\n",
      "2021.0    5\n",
      "2022.0    5\n",
      "2023.0    5\n",
      "Name: Single Race 6, dtype: int64\n",
      "Unique age groups per year:\n",
      "Year\n",
      "2004.0     8\n",
      "2005.0     8\n",
      "2006.0     8\n",
      "2007.0     8\n",
      "2008.0     8\n",
      "2009.0     8\n",
      "2010.0     8\n",
      "2011.0     8\n",
      "2012.0     8\n",
      "2013.0     8\n",
      "2014.0     8\n",
      "2015.0     8\n",
      "2016.0     8\n",
      "2017.0     8\n",
      "2018.0     8\n",
      "2019.0     8\n",
      "2020.0     9\n",
      "2021.0     9\n",
      "2022.0    10\n",
      "2023.0    10\n",
      "Name: Ten-Year Age Groups, dtype: int64\n",
      "States reporting per year:\n",
      "Year\n",
      "2004.0    50\n",
      "2005.0    48\n",
      "2006.0    50\n",
      "2007.0    50\n",
      "2008.0    51\n",
      "2009.0    51\n",
      "2010.0    50\n",
      "2011.0    50\n",
      "2012.0    50\n",
      "2013.0    50\n",
      "2014.0    51\n",
      "2015.0    51\n",
      "2016.0    51\n",
      "2017.0    51\n",
      "2018.0    51\n",
      "2019.0    51\n",
      "2020.0    51\n",
      "2021.0    51\n",
      "2022.0    51\n",
      "2023.0    51\n",
      "Name: State, dtype: int64\n",
      "Unreliable entries per year:\n",
      "Year\n",
      "2004.0     92\n",
      "2005.0     93\n",
      "2006.0     95\n",
      "2007.0    111\n",
      "2008.0     97\n",
      "2009.0    112\n",
      "2010.0    101\n",
      "2011.0     90\n",
      "2012.0    116\n",
      "2013.0    103\n",
      "2014.0    104\n",
      "2015.0    128\n",
      "2016.0    112\n",
      "2017.0    125\n",
      "2018.0    111\n",
      "2019.0    122\n",
      "2020.0    114\n",
      "2021.0    111\n",
      "2022.0    125\n",
      "2023.0    114\n",
      "dtype: int64\n",
      "Races in 2004-2017: {'Asian or Pacific Islander', nan, 'Black or African American', 'White', 'American Indian or Alaska Native'}\n",
      "Races in 2018-2023: {'Native Hawaiian or Other Pacific Islander', nan, 'Asian', 'Black or African American', 'White', 'American Indian or Alaska Native'}\n",
      "Missing from older data: {'Asian', 'Native Hawaiian or Other Pacific Islander'}\n",
      "Missing from newer data: {'Asian or Pacific Islander'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaish\\AppData\\Local\\Temp\\ipykernel_14696\\3353774545.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  unreliable_pattern = opioid_deaths.groupby('Year').apply(\n"
     ]
    }
   ],
   "source": [
    "# 1. Race categories - verify same races appear throughout timespan\n",
    "race_by_year = opioid_deaths.groupby('Year')['Single Race 6'].nunique()\n",
    "print(\"Unique races per year:\")\n",
    "print(race_by_year)\n",
    "\n",
    "# 2. Age groups - confirm consistent age groupings  \n",
    "age_by_year = opioid_deaths.groupby('Year')['Ten-Year Age Groups'].nunique()\n",
    "print(\"Unique age groups per year:\")\n",
    "print(age_by_year)\n",
    "\n",
    "# 3. Geographic coverage - check for missing states/years\n",
    "state_year_coverage = opioid_deaths.groupby('Year')['State'].nunique()\n",
    "print(\"States reporting per year:\")\n",
    "print(state_year_coverage)\n",
    "\n",
    "# 4. \"Unreliable\" patterns - document suppression trends\n",
    "unreliable_pattern = opioid_deaths.groupby('Year').apply(\n",
    "    lambda x: (x['Crude Rate'] == 'Unreliable').sum()\n",
    ")\n",
    "print(\"Unreliable entries per year:\")\n",
    "print(unreliable_pattern)\n",
    "\n",
    "# Find which race appears in newer data but not older\n",
    "races_old = set(dataset_2004_2017['Single Race 6'].unique())\n",
    "races_new = set(dataset_2018_2023['Single Race 6'].unique())\n",
    "\n",
    "print(\"Races in 2004-2017:\", races_old)\n",
    "print(\"Races in 2018-2023:\", races_new)\n",
    "print(\"Missing from older data:\", races_new - races_old)\n",
    "print(\"Missing from newer data:\", races_old - races_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5731e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ COLLECTING POPULATION DATA FOR ALL YEARS\n",
      "============================================================\n",
      "üìä Collecting population data for all years 1999-2023...\n",
      "This might take a few minutes...\n",
      "\n",
      "üîç Trying ACS 5-year estimates (2009-2023)...\n",
      "  üìÖ Getting 2009... ‚ùå 400 Client Error:  for url: https://api.census.gov/data/2009/acs/acs5?get=B01003_001E%2CB19013_001E%2CB23025_005E%2CB23025_002E%2CB25003_001E%2CNAME&for=state%3A%2A&key=a2fa499d96110671df7e4e2b0ac6db3e224e81da\n",
      "  üìÖ Getting 2010... ‚ùå 400 Client Error:  for url: https://api.census.gov/data/2010/acs/acs5?get=B01003_001E%2CB19013_001E%2CB23025_005E%2CB23025_002E%2CB25003_001E%2CNAME&for=state%3A%2A&key=a2fa499d96110671df7e4e2b0ac6db3e224e81da\n",
      "  üìÖ Getting 2011... ‚úÖ\n",
      "  üìÖ Getting 2012... ‚úÖ\n",
      "  üìÖ Getting 2013... ‚úÖ\n",
      "  üìÖ Getting 2014... ‚úÖ\n",
      "  üìÖ Getting 2015... ‚úÖ\n",
      "  üìÖ Getting 2016... ‚úÖ\n",
      "  üìÖ Getting 2017... ‚úÖ\n",
      "  üìÖ Getting 2018... ‚úÖ\n",
      "  üìÖ Getting 2019... ‚úÖ\n",
      "  üìÖ Getting 2020... ‚úÖ\n",
      "  üìÖ Getting 2021... ‚úÖ\n",
      "  üìÖ Getting 2022... ‚úÖ\n",
      "  üìÖ Getting 2023... ‚úÖ\n",
      "\n",
      "üîç Trying Population Estimates for earlier years...\n",
      "\n",
      "‚úÖ SUCCESS! Collected 676 records\n",
      "üìÖ Years: 2011 - 2023\n",
      "üèõÔ∏è States per year: ~52\n",
      "üíæ Saved to: population_data_all_years.csv\n",
      "\n",
      "üìä Data Coverage by Year:\n",
      "  2011: 52 states, 52 with population data\n",
      "  2012: 52 states, 52 with population data\n",
      "  2013: 52 states, 52 with population data\n",
      "  2014: 52 states, 52 with population data\n",
      "  2015: 52 states, 52 with population data\n",
      "  2016: 52 states, 52 with population data\n",
      "  2017: 52 states, 52 with population data\n",
      "  2018: 52 states, 52 with population data\n",
      "  2019: 52 states, 52 with population data\n",
      "  2020: 52 states, 52 with population data\n",
      "  2021: 52 states, 52 with population data\n",
      "  2022: 52 states, 52 with population data\n",
      "  2023: 52 states, 52 with population data\n",
      "\n",
      "üìã SUMMARY:\n",
      "  ‚úÖ Total records: 676\n",
      "  ‚ö†Ô∏è Missing years: [1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010]\n",
      "\n",
      "üîß For missing years (1999-2008), we can:\n",
      "  1. Use linear interpolation between known data points\n",
      "  2. Apply average growth rates\n",
      "  3. Use decennial census data as anchors (2000, 2010)\n",
      "  üí° For now, let's see what years we successfully collected...\n",
      "\n",
      "‚úÖ Ready to combine with your death data!\n"
     ]
    }
   ],
   "source": [
    "# Collect Population Data for All Years (1999-2023)\n",
    "# This will get population data to match your death data\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# PUT YOUR API KEY HERE (same as before)\n",
    "MY_API_KEY = \"a2fa499d96110671df7e4e2b0ac6db3e224e81da\"  # Replace with your actual key\n",
    "\n",
    "def collect_population_all_years():\n",
    "    \"\"\"Get population data for 1999-2023 to match death data\"\"\"\n",
    "    \n",
    "    print(\"üìä Collecting population data for all years 1999-2023...\")\n",
    "    print(\"This might take a few minutes...\")\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    # Different Census datasets for different year ranges\n",
    "    year_ranges = [\n",
    "        # ACS 5-year estimates (2009-2023)\n",
    "        {\"years\": list(range(2009, 2024)), \"dataset\": \"acs/acs5\", \"name\": \"ACS 5-year\"},\n",
    "        \n",
    "        # ACS 1-year estimates for some years (2005-2023, but not all years available)\n",
    "        {\"years\": [2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005], \n",
    "         \"dataset\": \"acs/acs1\", \"name\": \"ACS 1-year\"},\n",
    "        \n",
    "        # Population estimates (available for most years)\n",
    "        {\"years\": list(range(2010, 2024)), \"dataset\": \"pep/population\", \"name\": \"Population Estimates\"}\n",
    "    ]\n",
    "    \n",
    "    # Try ACS 5-year first (most reliable)\n",
    "    print(\"\\nüîç Trying ACS 5-year estimates (2009-2023)...\")\n",
    "    \n",
    "    for year in range(2009, 2024):\n",
    "        print(f\"  üìÖ Getting {year}...\", end=\" \")\n",
    "        \n",
    "        try:\n",
    "            url = f\"https://api.census.gov/data/{year}/acs/acs5\"\n",
    "            \n",
    "            # Basic variables we need\n",
    "            variables = [\n",
    "                \"B01003_001E\",  # Total Population\n",
    "                \"B19013_001E\",  # Median Household Income  \n",
    "                \"B23025_005E\",  # Unemployed\n",
    "                \"B23025_002E\",  # Labor Force\n",
    "                \"B25003_001E\",  # Housing Units\n",
    "                \"NAME\"\n",
    "            ]\n",
    "            \n",
    "            params = {\n",
    "                \"get\": \",\".join(variables),\n",
    "                \"for\": \"state:*\",\n",
    "                \"key\": MY_API_KEY\n",
    "            }\n",
    "            \n",
    "            response = requests.get(url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data[1:], columns=data[0])\n",
    "            df['year'] = year\n",
    "            df['data_source'] = f'ACS_5yr_{year}'\n",
    "            \n",
    "            all_data.append(df)\n",
    "            print(\"‚úÖ\")\n",
    "            \n",
    "            time.sleep(0.5)  # Be nice to the API\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {e}\")\n",
    "            continue\n",
    "    \n",
    "    # For earlier years (1999-2008), try Population Estimates\n",
    "    print(f\"\\nüîç Trying Population Estimates for earlier years...\")\n",
    "    \n",
    "    # Population estimates are available but with fewer variables\n",
    "    for year in range(2010, 2024):  # Start with what's most likely to work\n",
    "        if year >= 2009:  # We already have ACS data for these\n",
    "            continue\n",
    "            \n",
    "        print(f\"  üìÖ Getting {year}...\", end=\" \")\n",
    "        \n",
    "        try:\n",
    "            # Try intercensal estimates\n",
    "            url = f\"https://api.census.gov/data/{year}/pep/population\"\n",
    "            \n",
    "            params = {\n",
    "                \"get\": \"POP,NAME\",\n",
    "                \"for\": \"state:*\",\n",
    "                \"key\": MY_API_KEY\n",
    "            }\n",
    "            \n",
    "            response = requests.get(url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data[1:], columns=data[0])\n",
    "            df['year'] = year\n",
    "            df['data_source'] = f'PopEst_{year}'\n",
    "            \n",
    "            # Rename to match our standard\n",
    "            df.rename(columns={'POP': 'B01003_001E'}, inplace=True)\n",
    "            \n",
    "            all_data.append(df)\n",
    "            print(\"‚úÖ\")\n",
    "            \n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {e}\")\n",
    "            continue\n",
    "    \n",
    "    if all_data:\n",
    "        # Combine all data\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # Standardize column names\n",
    "        combined_df.rename(columns={\n",
    "            'B01003_001E': 'total_population',\n",
    "            'B19013_001E': 'median_income',\n",
    "            'B23025_005E': 'unemployed', \n",
    "            'B23025_002E': 'labor_force',\n",
    "            'B25003_001E': 'housing_units',\n",
    "            'NAME': 'state_name'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        # Convert to numeric\n",
    "        numeric_cols = ['total_population', 'median_income', 'unemployed', 'labor_force', 'housing_units']\n",
    "        for col in numeric_cols:\n",
    "            if col in combined_df.columns:\n",
    "                combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
    "        \n",
    "        # Calculate unemployment rate where possible\n",
    "        if 'unemployed' in combined_df.columns and 'labor_force' in combined_df.columns:\n",
    "            combined_df['unemployment_rate'] = (combined_df['unemployed'] / combined_df['labor_force']) * 100\n",
    "        \n",
    "        # Clean up state names\n",
    "        if 'state_name' in combined_df.columns:\n",
    "            combined_df['state_name'] = combined_df['state_name'].str.strip()\n",
    "        \n",
    "        # Sort by year and state\n",
    "        combined_df = combined_df.sort_values(['year', 'state_name'])\n",
    "        \n",
    "        print(f\"\\n‚úÖ SUCCESS! Collected {len(combined_df)} records\")\n",
    "        print(f\"üìÖ Years: {combined_df['year'].min()} - {combined_df['year'].max()}\")\n",
    "        print(f\"üèõÔ∏è States per year: ~{combined_df.groupby('year').size().mean():.0f}\")\n",
    "        \n",
    "        # Save the data\n",
    "        combined_df.to_csv('population_data_all_years.csv', index=False)\n",
    "        print(f\"üíæ Saved to: population_data_all_years.csv\")\n",
    "        \n",
    "        # Show data coverage\n",
    "        print(f\"\\nüìä Data Coverage by Year:\")\n",
    "        coverage = combined_df.groupby('year').agg({\n",
    "            'state_name': 'count',\n",
    "            'total_population': lambda x: x.notna().sum()\n",
    "        }).reset_index()\n",
    "        \n",
    "        for _, row in coverage.iterrows():\n",
    "            year = int(row['year'])\n",
    "            states = int(row['state_name']) \n",
    "            pop_data = int(row['total_population'])\n",
    "            print(f\"  {year}: {states} states, {pop_data} with population data\")\n",
    "        \n",
    "        return combined_df\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå No population data collected\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def fill_missing_years():\n",
    "    \"\"\"For years we can't get from Census API, we'll interpolate\"\"\"\n",
    "    \n",
    "    print(f\"\\nüîß For missing years (1999-2008), we can:\")\n",
    "    print(f\"  1. Use linear interpolation between known data points\")\n",
    "    print(f\"  2. Apply average growth rates\")  \n",
    "    print(f\"  3. Use decennial census data as anchors (2000, 2010)\")\n",
    "    \n",
    "    # This is a placeholder - we'd implement interpolation logic here\n",
    "    print(f\"  üí° For now, let's see what years we successfully collected...\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function\"\"\"\n",
    "    \n",
    "    print(\"üöÄ COLLECTING POPULATION DATA FOR ALL YEARS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check API key\n",
    "    if \"YOUR_API_KEY_HERE\" in MY_API_KEY:\n",
    "        print(\"‚ùå Please update your API key in the script first!\")\n",
    "        return\n",
    "    \n",
    "    # Collect data\n",
    "    pop_data = collect_population_all_years()\n",
    "    \n",
    "    if not pop_data.empty:\n",
    "        \n",
    "        # Show what we got\n",
    "        print(f\"\\nüìã SUMMARY:\")\n",
    "        print(f\"  ‚úÖ Total records: {len(pop_data)}\")\n",
    "        \n",
    "        # Check for gaps\n",
    "        years_collected = sorted(pop_data['year'].unique())\n",
    "        years_needed = list(range(1999, 2024))\n",
    "        missing_years = [y for y in years_needed if y not in years_collected]\n",
    "        \n",
    "        if missing_years:\n",
    "            print(f\"  ‚ö†Ô∏è Missing years: {missing_years}\")\n",
    "            fill_missing_years()\n",
    "        else:\n",
    "            print(f\"  üéâ All years collected!\")\n",
    "            \n",
    "        print(f\"\\n‚úÖ Ready to combine with your death data!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå No data collected. Check your API key and connection.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
